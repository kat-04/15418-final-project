<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>3D Conway's Game of Life</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">3D Conway's Game of Life</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="elements.html">Demo</a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Final Report</h1>
                            <h2>Summary</h2>
							<p>We implemented sequential C++, parallel CUDA, and parallel OpenMP versions of Conway's Game of Life in 3D and compared their performance on a variety of test cases. Our source code can be found <a href="https://github.com/kat-04/kat-04.github.io.git">here</a>.</p>

                            <h2>Background</h2>
                            <p>Conway's Game of Life is a Turing complete zero-player cellular automaton, traditionally in 2D, that simulates basic evolution. After giving an initial configuration of alive or dead cells, the pattern evolves based on a set number of rules governed by the neighbors of each cell. For each iteration, each cell is updated as follows:</p>
                            <ol>
                                <li>A cell with <h:math>&le; 1</h:math> living neighbors <i>(underpopulation)</i></li>
                                <li>A cell with <h:math>&ge; 4</h:math> living neighbors dies <i>(overpopulation)</i></li>
                                <li>An empty cell with exactly 3 living neighbors becomes alive <i>(reproduction)</i></li>
                            </ol>
                            <p><span class="image right"><img src="images/oscillatorExample.jpg" alt="" /></span>Despite this basic ruleset, there have been many different types of patterns found through studies: still lifes, which do not move; oscillators, which have a periodic form of motion; and spaceships, which drift in a consistent manner across space. Some initial patterns can also lead to infinite growth, where the bounding box of the pattern grows at each timestep. One example of a basic oscillator is shown to the right.</p>
                            <p>Conway's Game of Life is fairly simple in 2D, as there are only 8 neighbors and 2 axes (x- and y-axis). However, adapting to 3D -- increasing the number of neighbors from 8 to 26 and multiplying the size of the grid by another factor -- greatly increases communication intensity. Adapting to 3D also introduces the dilemna of how to define the neighbors of a cell. There are two commonly recognized neighborhoods for 3D Game of Life: the Moore neighborhood and the Von Neumann neighborhood. The Von Neumann neighborhood includes only the six cells that share a face with the current one, whereas the Moore neighborhood brings the number up to 26 by including diagonally adjacent cells. In our tests, we experiment with both to see the effect these neighborhoods have on communication intensity. </p>
                            <p>Each iteration ("frame") must be done sequentially as the input for the next frame is the output of the previous. Within a frame, however, each cell's update is completely independent. Thus, this algorithm can be parallelized over each cell in the frame. There are a large number of cell updates, each of which does the same set of operations, so this program is amenable to SIMD execution.</p>                            
                            <p>Another area for potential speedup is the idea converging or stable structures that form in Conway's Game of Life. In the 2D model, all starting states gradually converge to stable structures. Similarly, in 3D, some starting states will become stable after a certain time, meaning that there will be no need to pass information about empty spaces around unless they are immediate neighbors.</p>
                            <p>In order to thoroughly test our implementations, we also test a variety of rule-sets (each of which change the number of neighbors required for the rules listed above), which result in vastly different structures. Some create geometric, fractal-like patterns, some are very sparse, and others create dense, organic structures.</p>
                        
                            <h2>Our Approach</h2>
                            <h3>Sequential Implementation</h3>
                            <p>Our sequential implementation, written in C++, takes a fairly straightforward approach to this algorithm. For each frame, it loops over each cell. For each cell, it checks each of its neighbors, decides what the status of the cell should be, and writes it to the output. This idea is similar to those used in the online resources discussing 3D game of life.</p>
                            <p>This approach, while naive, allows us to easily check the correctness of the algorithm. Running this implementation on a variety of smaller test cases, we manually checked the output to double check that this version was correct. With this verified version, we are then able to check our complex parallel implementations' outputs against the sequential output for correctness.</p>
                            <h3>CUDA Implementation</h3>
                            <u>Idea</u>
                            <p>The CUDA implementation borrows the general code structure from Assignment 2's CUDA renderer. It uses a C++ file to call a few CUDA functions each frame and to time the algorithm. Before starting the first iteration, the input is processed and loaded into CUDA's global constant memory as a 1D array of integers. Since each voxel can only be in one of two states, we store each voxel's status as one bit of one of the integers in this array (allowing us to shrink the required memory by a factor of 8). In other words, each 8 bit integer in our global memory stores the status of 8 voxels.</p>
                            <p>Once the array and a few other constants have been loaded in, we begin the main iteration loop. Each frame, we do one iteration with a kernel, copy the result from the GPU to the CPU and write to output, and copy the output into the input array for the next iteration. </p>
                            <p>There are two versions of the kernel -- one for Moore and one for Von Neumann. They compute their cells' neighbors slightly differently, but the underlying principles are the same. Note that only one is called for the duration of the program execution as the rule set stays constant for a given test case. When the relevant kernel is called, we task each thread with one integer's updates (8 voxels). Thus, we use a rounded up grid size of <i>cubeVolume / (8 * blockSize)</i> to launch the correct number of threads for the task. For each of the 8 voxels, we use bit-wise operations to compute the neighboring indices and retrieve their statuses. Finally, this information is used to write the current voxel's new status to the output. </p>
                            <p>After the kernel finishes, the resulting data must be copied from the GPU to the CPU so that it can be written to the frame's output file. Furthermore, we copy the results back into the input array in the GPU for the next iteration. These memcpy calls take up the bulk of the CUDA algorithm's total runtime. </p>
                            <p>One optimization we implemented, but did not end up using, was creating a 3D bounding box around the active section of cells. Since we only need to look at the active cells and their neighbors during an update, calling only enough threads to look at the smaller active cube reduces the workload in unbalanced test cases. This optimization obtained up to a 10 times speedup on our corner case when only considering the time taken for the update computations, but it creates too much extra work to be worth the speedup.</p>
                            <p>Since we allow a variety of rule-sets, we cannot make any guarantees about how the bounding box will change between iterations. Thus, we need to check the status of each voxel in the output every frame to determine the new global minimum and maximum alive coordinates. We implemented a kernel to do this more efficiently; it computes a section's local min/max and then atomically updates the global values with its results. Using these atomic operations, however, delayed the threads significantly as each thread may be stalled while another was accessing the variables and more than outweighed the benefits of the bounding box. Our final code still allows the bounding box idea to be toggled on, but we do not use it when timing our final results.
                            <u>Strengths</u>
                            <p>Of the three implementations, the CUDA version has the fastest simulation times for almost all test cases (OpenMP performed better on extremely small tests with unbalanced data). In this implementation, simulation time refers to the sum of the time each frame takes to do just its update with the kernel. </p>
                            <p>Its high computation speed likely stems from the inherently data parallel approach of our core algorithm. Each cell does the same operations when updating, so the problem maps nicely to CUDA's data parallel execution on the GPU. In other words, each warp can run its threads with little to no divergent execution, so it has good SIMD utilization. </p>
                            <p>This implementation also takes advantage of some locality. We store voxels states in sorted order (by converting 3D coordinates to a linear index), so each thread updates 8 voxels that are adjacent on the x-axis. Furthermore, each of these voxels will have similar neighbors, so the neighbor status look-ups are often on the same cache line (or even within the same integer). It is difficult to have more locality than this due to the 3D nature of the problem and the existence of 26 neighbors per cell. </p>
                            <u>Limitations</u>
                            <p>While simulation time is exceptionally fast, the overall time does not achieve the same level of speedup. On dense cases it slightly outperfroms OpenMP, but OpenMP surpasses it by a factor of 100 on sparse cases. It does still, however, almost always outperform sequential (sequential does better on extremely small cases when CUDA overhead dominates). CUDA struggles with overall time due to the multiple memcpy operations in must do on the entire data array each frame. Copying to and from the CPU to GPU is costly, and doing so on large data sets for every frame limits this implementation's performance. </p>
                            <p>Another limitation of this implementation is the GPU's available memory. The implementation will fail to allocate memory on cubes with side length 4096 and above using GHC machines, as storing (4096^3 / 8) bytes = (4096<sup>3</sup>/8)/1024<sup>3</sup> = 8 GB in an array reaches the limit of NVIDIA GeForce RTX 2080's 8 GB of memory.</p>
                            <h3>OpenMP Implementation</h3>
                        
                        </div>
                        </div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
